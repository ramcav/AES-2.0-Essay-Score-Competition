{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e3643af",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-05-21T22:00:22.098392Z",
     "iopub.status.busy": "2024-05-21T22:00:22.097900Z",
     "iopub.status.idle": "2024-05-21T22:00:23.107313Z",
     "shell.execute_reply": "2024-05-21T22:00:23.106111Z"
    },
    "papermill": {
     "duration": 1.021652,
     "end_time": "2024-05-21T22:00:23.110091",
     "exception": false,
     "start_time": "2024-05-21T22:00:22.088439",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/learning-agency-lab-automated-essay-scoring-2/sample_submission.csv\n",
      "/kaggle/input/learning-agency-lab-automated-essay-scoring-2/train.csv\n",
      "/kaggle/input/learning-agency-lab-automated-essay-scoring-2/test.csv\n",
      "/kaggle/input/libraries/textstat-0.7.3-py3-none-any.whl\n",
      "/kaggle/input/libraries/pyspellchecker-0.8.1-py3-none-any.whl\n",
      "/kaggle/input/libraries/pyphen-0.15.0-py3-none-any.whl\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "244d8ff4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-21T22:00:23.126224Z",
     "iopub.status.busy": "2024-05-21T22:00:23.125701Z",
     "iopub.status.idle": "2024-05-21T22:02:08.772729Z",
     "shell.execute_reply": "2024-05-21T22:02:08.771466Z"
    },
    "papermill": {
     "duration": 105.657918,
     "end_time": "2024-05-21T22:02:08.775584",
     "exception": false,
     "start_time": "2024-05-21T22:00:23.117666",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /kaggle/input/libraries/pyphen-0.15.0-py3-none-any.whl\r\n",
      "Installing collected packages: pyphen\r\n",
      "Successfully installed pyphen-0.15.0\r\n",
      "Processing /kaggle/input/libraries/pyspellchecker-0.8.1-py3-none-any.whl\r\n",
      "Installing collected packages: pyspellchecker\r\n",
      "Successfully installed pyspellchecker-0.8.1\r\n",
      "Processing /kaggle/input/libraries/textstat-0.7.3-py3-none-any.whl\r\n",
      "Requirement already satisfied: pyphen in /opt/conda/lib/python3.10/site-packages (from textstat==0.7.3) (0.15.0)\r\n",
      "Installing collected packages: textstat\r\n",
      "Successfully installed textstat-0.7.3\r\n"
     ]
    }
   ],
   "source": [
    "!pip install \"/kaggle/input/libraries/pyphen-0.15.0-py3-none-any.whl\"\n",
    "!pip install \"/kaggle/input/libraries/pyspellchecker-0.8.1-py3-none-any.whl\"\n",
    "!pip install \"/kaggle/input/libraries/textstat-0.7.3-py3-none-any.whl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e9892895",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-21T22:02:08.793285Z",
     "iopub.status.busy": "2024-05-21T22:02:08.792867Z",
     "iopub.status.idle": "2024-05-21T22:02:10.251618Z",
     "shell.execute_reply": "2024-05-21T22:02:10.250375Z"
    },
    "papermill": {
     "duration": 1.470995,
     "end_time": "2024-05-21T22:02:10.254467",
     "exception": false,
     "start_time": "2024-05-21T22:02:08.783472",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  /usr/share/nltk_data/corpora/wordnet.zip\r\n",
      "   creating: /usr/share/nltk_data/corpora/wordnet/\r\n",
      "  inflating: /usr/share/nltk_data/corpora/wordnet/lexnames  \r\n",
      "  inflating: /usr/share/nltk_data/corpora/wordnet/data.verb  \r\n",
      "  inflating: /usr/share/nltk_data/corpora/wordnet/index.adv  \r\n",
      "  inflating: /usr/share/nltk_data/corpora/wordnet/adv.exc  \r\n",
      "  inflating: /usr/share/nltk_data/corpora/wordnet/index.verb  \r\n",
      "  inflating: /usr/share/nltk_data/corpora/wordnet/cntlist.rev  \r\n",
      "  inflating: /usr/share/nltk_data/corpora/wordnet/data.adj  \r\n",
      "  inflating: /usr/share/nltk_data/corpora/wordnet/index.adj  \r\n",
      "  inflating: /usr/share/nltk_data/corpora/wordnet/LICENSE  \r\n",
      "  inflating: /usr/share/nltk_data/corpora/wordnet/citation.bib  \r\n",
      "  inflating: /usr/share/nltk_data/corpora/wordnet/noun.exc  \r\n",
      "  inflating: /usr/share/nltk_data/corpora/wordnet/verb.exc  \r\n",
      "  inflating: /usr/share/nltk_data/corpora/wordnet/README  \r\n",
      "  inflating: /usr/share/nltk_data/corpora/wordnet/index.sense  \r\n",
      "  inflating: /usr/share/nltk_data/corpora/wordnet/data.noun  \r\n",
      "  inflating: /usr/share/nltk_data/corpora/wordnet/data.adv  \r\n",
      "  inflating: /usr/share/nltk_data/corpora/wordnet/index.noun  \r\n",
      "  inflating: /usr/share/nltk_data/corpora/wordnet/adj.exc  \r\n"
     ]
    }
   ],
   "source": [
    "!unzip /usr/share/nltk_data/corpora/wordnet.zip -d /usr/share/nltk_data/corpora/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0a52875e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-21T22:02:10.272882Z",
     "iopub.status.busy": "2024-05-21T22:02:10.272447Z",
     "iopub.status.idle": "2024-05-21T22:02:10.278650Z",
     "shell.execute_reply": "2024-05-21T22:02:10.277417Z"
    },
    "papermill": {
     "duration": 0.018355,
     "end_time": "2024-05-21T22:02:10.281059",
     "exception": false,
     "start_time": "2024-05-21T22:02:10.262704",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "BASE_PATH = '/kaggle/input/learning-agency-lab-automated-essay-scoring-2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e88717a8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-21T22:02:10.299162Z",
     "iopub.status.busy": "2024-05-21T22:02:10.298742Z",
     "iopub.status.idle": "2024-05-21T22:02:12.734926Z",
     "shell.execute_reply": "2024-05-21T22:02:12.733631Z"
    },
    "papermill": {
     "duration": 2.44827,
     "end_time": "2024-05-21T22:02:12.737471",
     "exception": false,
     "start_time": "2024-05-21T22:02:10.289201",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/nltk/twitter/__init__.py:20: UserWarning: The twython library has not been installed. Some functionality from the twitter package will not be available.\n",
      "  warnings.warn(\"The twython library has not been installed. \"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from sklearn.model_selection import train_test_split\n",
    "from spellchecker import SpellChecker\n",
    "from textstat import textstat\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from sklearn.model_selection import KFold,StratifiedKFold\n",
    "\n",
    "import pickle # To save models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f603342e",
   "metadata": {
    "papermill": {
     "duration": 0.007863,
     "end_time": "2024-05-21T22:02:12.753755",
     "exception": false,
     "start_time": "2024-05-21T22:02:12.745892",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 1. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "09b90382",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-21T22:02:12.772490Z",
     "iopub.status.busy": "2024-05-21T22:02:12.772097Z",
     "iopub.status.idle": "2024-05-21T22:02:12.799814Z",
     "shell.execute_reply": "2024-05-21T22:02:12.798697Z"
    },
    "papermill": {
     "duration": 0.040233,
     "end_time": "2024-05-21T22:02:12.802209",
     "exception": false,
     "start_time": "2024-05-21T22:02:12.761976",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# FEATURE ENGINEERING\n",
    "\n",
    "def feature_pipeline():\n",
    "    df = pd.read_csv(f'{BASE_PATH}/train.csv')\n",
    "    test_df = pd.read_csv(f'{BASE_PATH}/test.csv')\n",
    "    \n",
    "    train_df = df\n",
    "\n",
    "    print(\"---------CALCULATING ESSAY LENGTHS---------\")\n",
    "    train_df = calculate_essay_lengths(train_df, \"full_text\")\n",
    "    test_df = calculate_essay_lengths(test_df, \"full_text\")\n",
    "    print(\"---------FINISHED CALCULATING ESSAY LENGTHS---------\\n\")\n",
    "\n",
    "    print(\"---------ANALYZING SENTIMENTS---------\")\n",
    "    train_df = analyze_sentiment(train_df, \"full_text\")\n",
    "    test_df = analyze_sentiment(test_df, \"full_text\")\n",
    "    print(\"---------FINISHED ANALYZING SENTIMENTS---------\\n\")\n",
    "\n",
    "    print(\"---------ANALYZING READABILITY---------\")\n",
    "    readability_train_df = analyze_readability(train_df, \"full_text\")\n",
    "    train_df[\"fkg_score\"] = readability_train_df[\"Flesch-Kincaid\"]\n",
    "    train_df[\"gf_score\"] = readability_train_df[\"Gunning Fog\"]\n",
    "    readability_test_df = analyze_readability(test_df, \"full_text\")\n",
    "    test_df[\"fkg_score\"] = readability_test_df[\"Flesch-Kincaid\"]\n",
    "    test_df[\"gf_score\"] = readability_test_df[\"Gunning Fog\"]\n",
    "    print(\"---------FINISHED ANALYZING READABILITY---------\\n\")\n",
    "\n",
    "    print(\"---------ANALYZING LEXICAL DIVERSITY AND SPELLING MISTAKES---------\")\n",
    "    train_df = lexical_diversity_and_mistakes(train_df, \"full_text\")\n",
    "    test_df = lexical_diversity_and_mistakes(test_df, \"full_text\")\n",
    "    print(\"---------FINISHED ANALYZING LEXICAL DIVERSITY AND SPELLING MISTAKES---------\\n\")\n",
    "\n",
    "    print(\"---------GETTING DIFFICULT WORD COUNT---------\")\n",
    "    train_df = get_difficult_word_count(train_df, \"full_text\")\n",
    "    test_df = get_difficult_word_count(test_df, \"full_text\")\n",
    "    print(\"---------FINISHED GETTING DIFFICULT WORD COUNT---------\\n\")\n",
    "\n",
    "    return train_df, test_df\n",
    "\n",
    "                                                 \n",
    "# Helper Functions\n",
    "\n",
    "def calculate_essay_lengths(df, text_column):\n",
    "    df['char_essay_length'] = df[text_column].apply(len)\n",
    "    df['words_essay_length'] = df[text_column].apply(lambda x: len(x.split()))\n",
    "    df['sentence_essay_length'] = df[text_column].apply(lambda x: len(x.split('.')))\n",
    "    return df\n",
    "\n",
    "def analyze_sentiment(df, text_column):\n",
    "    # Initialize the sentiment analyzer\n",
    "    sid = SentimentIntensityAnalyzer()\n",
    "    \n",
    "    # Analyze the sentiment of each essay\n",
    "    sentiment_scores = df[text_column].apply(lambda x: sid.polarity_scores(x)['compound'])\n",
    "    \n",
    "    # Add sentiment scores to the dataframe\n",
    "    df['sentiment_score'] = sentiment_scores\n",
    "    \n",
    "    # Overall sentiment analysis\n",
    "    positive_count = sum(sentiment_scores > 0)\n",
    "    negative_count = sum(sentiment_scores < 0)\n",
    "    neutral_count = len(sentiment_scores) - positive_count - negative_count\n",
    "    \n",
    "    # Data for visualization\n",
    "    categories = ['Positive', 'Negative', 'Neutral']\n",
    "    counts = [positive_count, negative_count, neutral_count]\n",
    "    \n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "def analyze_readability(df, text_column):\n",
    "    # Analyzing readability scores for each essay\n",
    "    readability_scores = []\n",
    "    for essay in df[text_column]:\n",
    "        # Compute Flesch-Kincaid Grade Level\n",
    "        fkg_score = textstat.flesch_kincaid_grade(essay)\n",
    "        \n",
    "        # Compute Gunning Fog Index\n",
    "        gunning_fog_score = textstat.gunning_fog(essay)\n",
    "        \n",
    "        # Add scores to list\n",
    "        readability_scores.append({'Flesch-Kincaid': fkg_score, 'Gunning Fog': gunning_fog_score})\n",
    "    \n",
    "    # Creating a dataframe to store the scores\n",
    "    readability_df = pd.DataFrame(readability_scores)\n",
    "    \n",
    "    return readability_df\n",
    "\n",
    "# Inspo from https://www.kaggle.com/code/kuangank/ase-fighting\n",
    "def lexical_diversity_and_mistakes(df, text_column):\n",
    "    spell_checker = SpellChecker()\n",
    "    \n",
    "    lexical_diversities = []\n",
    "    spelling_mistake_counts = []\n",
    "    spelling_mistake_ratios = []\n",
    "    \n",
    "    for text in df[text_column]:\n",
    "        tokens = word_tokenize(text)\n",
    "        unique_tokens = set(tokens)\n",
    "        \n",
    "        # Calculate lexical diversity\n",
    "        if len(tokens) == 0:\n",
    "            lexical_diversity = 0\n",
    "        else:\n",
    "            lexical_diversity = len(unique_tokens) / len(tokens)\n",
    "        \n",
    "        # Calculate spelling mistakes\n",
    "        spelling_mistake_count = len(spell_checker.unknown(token for token in tokens if token.isalpha()))\n",
    "        \n",
    "        # Calculate spelling mistake ratio\n",
    "        if len(tokens) == 0:\n",
    "            spelling_mistake_ratio = 0\n",
    "        else:\n",
    "            spelling_mistake_ratio = spelling_mistake_count / len(tokens)\n",
    "        \n",
    "        lexical_diversities.append(lexical_diversity)\n",
    "        spelling_mistake_counts.append(spelling_mistake_count)\n",
    "        spelling_mistake_ratios.append(spelling_mistake_ratio)\n",
    "    \n",
    "    df['lexical_diversity'] = lexical_diversities\n",
    "    df['spelling_mistake_count'] = spelling_mistake_counts\n",
    "    df['spelling_mistake_ratio'] = spelling_mistake_ratios\n",
    "    \n",
    "    return df\n",
    "\n",
    "def get_difficult_word_count(df, text_column):\n",
    "    difficult_word_counts = []\n",
    "    difficult_word_ratios = []\n",
    "    \n",
    "    for text in df[text_column]:\n",
    "        tokens = word_tokenize(text)\n",
    "        \n",
    "        # Calculate difficult words\n",
    "        difficult_word_count = textstat.difficult_words(text)\n",
    "        \n",
    "        # Calculate difficult word ratio\n",
    "        if len(tokens) == 0:\n",
    "            difficult_word_ratio = 0\n",
    "        else:\n",
    "            difficult_word_ratio = difficult_word_count / len(tokens)\n",
    "        \n",
    "        difficult_word_counts.append(difficult_word_count)\n",
    "        difficult_word_ratios.append(difficult_word_ratio)\n",
    "    \n",
    "    df['difficult_words'] = difficult_word_counts\n",
    "    df['difficult_word_ratio'] = difficult_word_ratios\n",
    "    \n",
    "    return df\n",
    "\n",
    "    \n",
    "    train_dense = train_tfidf.toarray()\n",
    "    \n",
    "    train_tfidf_df = pd.DataFrame(train_dense, columns=[f'tfid_{i}' for i in range(train_dense.shape[1])])\n",
    "    \n",
    "    train_tfidf_df['essay_id'] = train_df['essay_id'].values\n",
    "    \n",
    "    train_df = train_df.merge(train_tfidf_df, on='essay_id', how='left')\n",
    "    \n",
    "    return train_df, test_df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "58a9ee4c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-21T22:02:12.820621Z",
     "iopub.status.busy": "2024-05-21T22:02:12.820218Z",
     "iopub.status.idle": "2024-05-21T22:08:23.223549Z",
     "shell.execute_reply": "2024-05-21T22:08:23.222426Z"
    },
    "papermill": {
     "duration": 370.423347,
     "end_time": "2024-05-21T22:08:23.234141",
     "exception": false,
     "start_time": "2024-05-21T22:02:12.810794",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------CALCULATING ESSAY LENGTHS---------\n",
      "---------FINISHED CALCULATING ESSAY LENGTHS---------\n",
      "\n",
      "---------ANALYZING SENTIMENTS---------\n",
      "---------FINISHED ANALYZING SENTIMENTS---------\n",
      "\n",
      "---------ANALYZING READABILITY---------\n",
      "---------FINISHED ANALYZING READABILITY---------\n",
      "\n",
      "---------ANALYZING LEXICAL DIVERSITY AND SPELLING MISTAKES---------\n",
      "---------FINISHED ANALYZING LEXICAL DIVERSITY AND SPELLING MISTAKES---------\n",
      "\n",
      "---------GETTING DIFFICULT WORD COUNT---------\n",
      "---------FINISHED GETTING DIFFICULT WORD COUNT---------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_feats, test_feats = feature_pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e0ad292d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-21T22:08:23.253515Z",
     "iopub.status.busy": "2024-05-21T22:08:23.253117Z",
     "iopub.status.idle": "2024-05-21T22:08:25.240305Z",
     "shell.execute_reply": "2024-05-21T22:08:25.239095Z"
    },
    "papermill": {
     "duration": 2.000275,
     "end_time": "2024-05-21T22:08:25.243192",
     "exception": false,
     "start_time": "2024-05-21T22:08:23.242917",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df = train_feats.copy()\n",
    "test_df = test_feats.copy()\n",
    "\n",
    "# Save\n",
    "train_df.to_csv('train_df.csv', index=False)\n",
    "test_df.to_csv('test_df.csv', index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "53936956",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-21T22:08:25.263456Z",
     "iopub.status.busy": "2024-05-21T22:08:25.263000Z",
     "iopub.status.idle": "2024-05-21T22:08:25.289297Z",
     "shell.execute_reply": "2024-05-21T22:08:25.288087Z"
    },
    "papermill": {
     "duration": 0.03933,
     "end_time": "2024-05-21T22:08:25.291869",
     "exception": false,
     "start_time": "2024-05-21T22:08:25.252539",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of       essay_id                                          full_text  score  \\\n",
       "0      000d118  Many people have car where they live. The thin...      3   \n",
       "1      000fe60  I am a scientist at NASA that is discussing th...      3   \n",
       "2      001ab80  People always wish they had the same technolog...      4   \n",
       "3      001bdc0  We all heard about Venus, the planet without a...      4   \n",
       "4      002ba53  Dear, State Senator\\n\\nThis is a letter to arg...      3   \n",
       "...        ...                                                ...    ...   \n",
       "17302  ffd378d  the story \" The Challenge of Exploing Venus \" ...      2   \n",
       "17303  ffddf1f  Technology has changed a lot of ways that we l...      4   \n",
       "17304  fff016d  If you don't like sitting around all day than ...      2   \n",
       "17305  fffb49b  In \"The Challenge of Exporing Venus,\" the auth...      1   \n",
       "17306  fffed3e  Venus is worthy place to study but dangerous. ...      2   \n",
       "\n",
       "       char_essay_length  words_essay_length  sentence_essay_length  \\\n",
       "0                   2677                 498                     14   \n",
       "1                   1669                 332                     20   \n",
       "2                   3077                 550                     25   \n",
       "3                   2701                 451                     24   \n",
       "4                   2208                 373                     16   \n",
       "...                  ...                 ...                    ...   \n",
       "17302                856                 157                     10   \n",
       "17303               3354                 579                     29   \n",
       "17304               1122                 215                     16   \n",
       "17305               1427                 231                     12   \n",
       "17306                786                 155                     13   \n",
       "\n",
       "       sentiment_score  fkg_score  gf_score  lexical_diversity  \\\n",
       "0               0.9937       14.7     17.33           0.455046   \n",
       "1               0.7705        5.4      7.48           0.452830   \n",
       "2              -0.9731        9.9     11.49           0.401653   \n",
       "3               0.9702       10.4     11.91           0.471624   \n",
       "4               0.9771       11.8     12.64           0.373206   \n",
       "...                ...        ...       ...                ...   \n",
       "17302           0.3626        7.6      9.72           0.580838   \n",
       "17303           0.9943       11.2     11.42           0.406832   \n",
       "17304           0.9803        4.1      6.28           0.485106   \n",
       "17305           0.9513       10.3     11.66           0.541667   \n",
       "17306           0.8294        4.8      5.93           0.583333   \n",
       "\n",
       "       spelling_mistake_count  spelling_mistake_ratio  difficult_words  \\\n",
       "0                          23                0.042202               60   \n",
       "1                           8                0.021563               24   \n",
       "2                           8                0.013223               67   \n",
       "3                           7                0.013699               78   \n",
       "4                           8                0.019139               55   \n",
       "...                       ...                     ...              ...   \n",
       "17302                      13                0.077844               22   \n",
       "17303                      16                0.024845               74   \n",
       "17304                       2                0.008511               12   \n",
       "17305                       6                0.022727               50   \n",
       "17306                       8                0.047619               16   \n",
       "\n",
       "       difficult_word_ratio  \n",
       "0                  0.110092  \n",
       "1                  0.064690  \n",
       "2                  0.110744  \n",
       "3                  0.152642  \n",
       "4                  0.131579  \n",
       "...                     ...  \n",
       "17302              0.131737  \n",
       "17303              0.114907  \n",
       "17304              0.051064  \n",
       "17305              0.189394  \n",
       "17306              0.095238  \n",
       "\n",
       "[17307 rows x 14 columns]>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d5fc901c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-21T22:08:25.312730Z",
     "iopub.status.busy": "2024-05-21T22:08:25.312338Z",
     "iopub.status.idle": "2024-05-21T22:08:25.319920Z",
     "shell.execute_reply": "2024-05-21T22:08:25.318756Z"
    },
    "papermill": {
     "duration": 0.021044,
     "end_time": "2024-05-21T22:08:25.322458",
     "exception": false,
     "start_time": "2024-05-21T22:08:25.301414",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17307, 14)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d32ba8ef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-21T22:08:25.342819Z",
     "iopub.status.busy": "2024-05-21T22:08:25.342455Z",
     "iopub.status.idle": "2024-05-21T22:08:25.365386Z",
     "shell.execute_reply": "2024-05-21T22:08:25.364075Z"
    },
    "papermill": {
     "duration": 0.036423,
     "end_time": "2024-05-21T22:08:25.368322",
     "exception": false,
     "start_time": "2024-05-21T22:08:25.331899",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "train_df = train_df.dropna()\n",
    "\n",
    "# Verify that there are no more NaN values\n",
    "print(train_df.isnull().sum().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dd752070",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-21T22:08:25.389983Z",
     "iopub.status.busy": "2024-05-21T22:08:25.389553Z",
     "iopub.status.idle": "2024-05-21T22:08:25.396314Z",
     "shell.execute_reply": "2024-05-21T22:08:25.395209Z"
    },
    "papermill": {
     "duration": 0.019762,
     "end_time": "2024-05-21T22:08:25.398652",
     "exception": false,
     "start_time": "2024-05-21T22:08:25.378890",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17307, 14)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5cf8fef8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-21T22:08:25.419548Z",
     "iopub.status.busy": "2024-05-21T22:08:25.419150Z",
     "iopub.status.idle": "2024-05-21T22:08:25.427969Z",
     "shell.execute_reply": "2024-05-21T22:08:25.426791Z"
    },
    "papermill": {
     "duration": 0.022198,
     "end_time": "2024-05-21T22:08:25.430535",
     "exception": false,
     "start_time": "2024-05-21T22:08:25.408337",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Separate features and target variable from training and validation data\n",
    "X_train = train_df.drop(columns=['essay_id', 'full_text','score'])  # Drop target column\n",
    "y_train = train_df['score']  # Target column\n",
    "\n",
    "test = test_df.drop(columns=['essay_id', 'full_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7617a0d7",
   "metadata": {
    "papermill": {
     "duration": 0.009581,
     "end_time": "2024-05-21T22:08:25.450300",
     "exception": false,
     "start_time": "2024-05-21T22:08:25.440719",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "60ef56d2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-21T22:08:25.472124Z",
     "iopub.status.busy": "2024-05-21T22:08:25.470779Z",
     "iopub.status.idle": "2024-05-21T22:08:38.049678Z",
     "shell.execute_reply": "2024-05-21T22:08:38.048497Z"
    },
    "papermill": {
     "duration": 12.59301,
     "end_time": "2024-05-21T22:08:38.052834",
     "exception": false,
     "start_time": "2024-05-21T22:08:25.459824",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Initialize the Random Forest classifier\n",
    "rf_model = RandomForestClassifier(n_estimators=500, random_state=42, n_jobs=-1)\n",
    "\n",
    "# Train the model\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Save the trained model to a file using pickle\n",
    "with open(\"random_forest_model.pkl\", \"wb\") as f:\n",
    "    pickle.dump(rf_model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "278d803e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-21T22:08:38.074597Z",
     "iopub.status.busy": "2024-05-21T22:08:38.074138Z",
     "iopub.status.idle": "2024-05-21T22:08:38.944873Z",
     "shell.execute_reply": "2024-05-21T22:08:38.943564Z"
    },
    "papermill": {
     "duration": 0.885234,
     "end_time": "2024-05-21T22:08:38.947827",
     "exception": false,
     "start_time": "2024-05-21T22:08:38.062593",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(\"random_forest_model.pkl\", \"rb\") as f:\n",
    "    loaded_rf_model = pickle.load(f)\n",
    "\n",
    "# Make predictions on the validation set using the loaded model\n",
    "y_pred = loaded_rf_model.predict(test)\n",
    "\n",
    "# Assuming `test` DataFrame has an 'id' column and your predictions are stored in `y_pred`\n",
    "submission_df = pd.DataFrame({\n",
    "    'id': test_df['essay_id'],  # Make sure 'id' matches the name of your ID column\n",
    "    'prediction': y_pred\n",
    "})\n",
    "\n",
    "# Save the submission DataFrame to a CSV file\n",
    "submission_df.to_csv('submission.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cc9427f0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-21T22:08:38.970151Z",
     "iopub.status.busy": "2024-05-21T22:08:38.969113Z",
     "iopub.status.idle": "2024-05-21T22:08:38.975239Z",
     "shell.execute_reply": "2024-05-21T22:08:38.973960Z"
    },
    "papermill": {
     "duration": 0.020085,
     "end_time": "2024-05-21T22:08:38.977606",
     "exception": false,
     "start_time": "2024-05-21T22:08:38.957521",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.model_selection import cross_val_score\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # Define a range of values for n_estimators\n",
    "# n_estimators_range = [10, 50, 100, 200, 500, 1000]\n",
    "\n",
    "# # Evaluate the model using cross-validation with parallel processing\n",
    "# scores = []\n",
    "# for n_estimators in n_estimators_range:\n",
    "#     rf_model = RandomForestClassifier(n_estimators=n_estimators, random_state=42, n_jobs=-1)  # n_jobs=-1 uses all available cores\n",
    "#     score = cross_val_score(rf_model, X_train, y_train, cv=5, scoring='accuracy', n_jobs=-1).mean()  # n_jobs=-1 uses all available cores\n",
    "#     scores.append(score)\n",
    "#     print(f'n_estimators: {n_estimators}, Cross-Validation Accuracy: {score:.4f}')\n",
    "\n",
    "# # Plot the results\n",
    "# plt.plot(n_estimators_range, scores)\n",
    "# plt.xlabel('Number of Trees')\n",
    "# plt.ylabel('Cross-Validation Accuracy')\n",
    "# plt.title('Effect of Number of Trees on Model Performance')\n",
    "# plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 8059942,
     "sourceId": 71485,
     "sourceType": "competition"
    },
    {
     "datasetId": 5057592,
     "sourceId": 8479768,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30698,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 501.381579,
   "end_time": "2024-05-21T22:08:40.315176",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-05-21T22:00:18.933597",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
